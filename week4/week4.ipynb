{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ1zw-8Ijgn3",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchaudio.__version__)\n",
        "\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install librosa\n",
        "!pip install transformers torch torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "from matplotlib.patches import Rectangle\n",
        "from torchaudio.utils import download_asset\n",
        "\n",
        "torch.random.manual_seed(0)"
      ],
      "metadata": {
        "id": "tqvPsjThdBEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997222ac-3355-435d-ca7b-3f08e78373c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c5ba4658350>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 경로를 로컬 m4a 파일로 변경\n",
        "M4A_FILE_PATH = \"/content/911.m4a\"\n",
        "\n",
        "try:\n",
        "    SPEECH_WAVEFORM, SAMPLE_RATE = torchaudio.load(M4A_FILE_PATH)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"m4a 파일 로드 실패: {e}\")"
      ],
      "metadata": {
        "id": "giDs_twKLkir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d457dd-594e-414b-d20a-25f60957e929"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sample_rate 16000으로 변경\n",
        "target_sample_rate = 16000\n",
        "if SAMPLE_RATE != target_sample_rate:\n",
        "    resampler = torchaudio.transforms.Resample(orig_freq=SAMPLE_RATE, new_freq=target_sample_rate)\n",
        "    resampled_waveform = resampler(SPEECH_WAVEFORM)\n",
        "else:\n",
        "    resampled_waveform = SPEECH_WAVEFORM"
      ],
      "metadata": {
        "id": "d7SKDIdggof4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "model_name = \"facebook/wav2vec2-base-960h\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "u-82BGnzgwFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_values = processor(resampled_waveform.squeeze(), return_tensors=\"pt\", sampling_rate=target_sample_rate).input_values"
      ],
      "metadata": {
        "id": "njuOO_3rgwrB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(input_values).logits\n",
        "\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "transcription = processor.batch_decode(predicted_ids)"
      ],
      "metadata": {
        "id": "bpSkv1Cog2Dz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-\" * 20)\n",
        "print(f\"인식된 문장: {transcription[0]}\")\n",
        "print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRzlkylAhNXK",
        "outputId": "959e9a5a-6879-4d96-febb-63cd4f2c29e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "인식된 문장: NINE ONE ONE WHAT IS YOUR EMERGENCY\n",
            "--------------------\n"
          ]
        }
      ]
    }
  ]
}